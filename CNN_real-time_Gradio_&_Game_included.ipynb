{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494ffc15-90b1-4d0d-ab13-864da980267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1cad5df-a939-44bf-b433-6ce842ed4a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x15d5a0ef3d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from skimage import io, transform\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5964ab95-d55b-4566-abe8-1e83677718ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410b8ad2-4131-45ab-974d-1f5e778af817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15.2+cu118\n"
     ]
    }
   ],
   "source": [
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bac5a4f-c53f-4f4f-8934-d1679b7394e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae1f5cd5-3786-4ff6-b0da-b9b470397d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b53b0db-2924-460a-84e9-7e3bc90b1936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best.pt\n",
      "CNN_0.962963.pt\n",
      "MLP_0.761364.pt\n",
      "MLP_0.851064.pt\n",
      "MLP_0.872340.pt\n",
      "MLP_0.888889new_model3.pt\n",
      "MLP_0.893617.pt\n",
      "MLP_0.914894.pt\n",
      "MLP_0.919753.pt\n",
      "MLP_0.919753new_model2.pt\n",
      "MLP_0.932099new_model3.pt\n",
      "MLP_0.936170.pt\n",
      "MLP_0.936170_best.pt\n",
      "MLP_0.936170_old.pt\n",
      "MLP_0.938272new_model3.pt\n"
     ]
    }
   ],
   "source": [
    "for model_dir in os.listdir(\"./\"):\n",
    "    if model_dir.split(\".\")[-1] != \"pt\":\n",
    "        continue\n",
    "    print(model_dir)   \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee939d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9494c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import math\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "import gradio as gr\n",
    "import sounddevice as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9135dc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "CNN_Audio_Model(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation1): ReLU()\n",
      "  (dropout1): Dropout(p=0.1, inplace=False)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation2): ReLU()\n",
      "  (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation3): ReLU()\n",
      "  (dropout3): Dropout(p=0.1, inplace=False)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation4): ReLU()\n",
      "  (dropout4): Dropout(p=0.3, inplace=False)\n",
      "  (fc6): Linear(in_features=2560, out_features=128, bias=True)\n",
      "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation6): ReLU()\n",
      "  (dropout6): Dropout(p=0.5, inplace=False)\n",
      "  (fc7): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation7): ReLU()\n",
      "  (dropout7): Dropout(p=0.25, inplace=False)\n",
      "  (fc8): Linear(in_features=128, out_features=32, bias=True)\n",
      "  (bn8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation8): ReLU()\n",
      "  (dropout8): Dropout(p=0.25, inplace=False)\n",
      "  (fc9): Linear(in_features=32, out_features=4, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN_Audio_Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN_Audio_Model, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=\"same\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=\"same\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=\"same\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=64)\n",
    "        self.activation3 = torch.nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=\"same\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=64)\n",
    "        self.activation4 = torch.nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(p=0.3)\n",
    "        \n",
    "        fc_dim_in = 5 * 8 * 64\n",
    "        \n",
    "        self.fc6 = nn.Linear(in_features=fc_dim_in, out_features=128)\n",
    "        self.bn6 = nn.BatchNorm2d(num_features=128)\n",
    "        self.activation6 = torch.nn.ReLU()\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        \n",
    "        self.fc7 = nn.Linear(in_features=128, out_features=4)\n",
    "        self.bn7 = nn.BatchNorm2d(num_features=128)\n",
    "        self.activation7 = torch.nn.ReLU()\n",
    "        self.dropout7 = nn.Dropout(p=0.25)\n",
    "        \n",
    "        self.fc8 = nn.Linear(in_features=128, out_features=32)\n",
    "        self.bn8 = nn.BatchNorm2d(num_features=32)\n",
    "        self.activation8 = torch.nn.ReLU()\n",
    "        self.dropout8 = nn.Dropout(p=0.25)  \n",
    "        \n",
    "        self.fc9 = nn.Linear(in_features=32, out_features=4)\n",
    "        \n",
    "        self.softmax = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.pool3(x)\n",
    "        # x = self.dropout3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.activation4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "#         x = self.conv5(x)\n",
    "#         x = self.bn5(x)\n",
    "#         x = self.activation5(x)\n",
    "#         x = self.pool5(x)\n",
    "#         x = self.dropout5(x)\n",
    "        \n",
    "        # print(x.size())\n",
    "        fc_dim_in = 5 * 8 * 64\n",
    "        x = x.view(-1, fc_dim_in)\n",
    "        # print(x.size())\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        # x = self.bn6(x)\n",
    "        x = self.activation6(x)\n",
    "        x = self.dropout6(x)\n",
    "\n",
    "        x = self.fc7(x)\n",
    "        # x = self.bn7(x)\n",
    "        # x = self.activation7(x)\n",
    "        # x = self.dropout7(x)        \n",
    "\n",
    "#         x = self.fc8(x)\n",
    "#         x = self.bn8(x)\n",
    "#         x = self.activation8(x)\n",
    "#         x = self.dropout8(x)         \n",
    "\n",
    "#         x = self.fc9(x)\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        # return the output\n",
    "        return x\n",
    "\n",
    "CNN_model = CNN_Audio_Model()\n",
    "\n",
    "print('The model:')\n",
    "print(CNN_model)\n",
    "\n",
    "# print('\\n\\nModel params:')\n",
    "# for param in MLP_model.parameters():\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a615b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "model_path = current_dir + '\\\\' + \"CNN_0.962963.pt\"\n",
    "\n",
    "test_model = CNN_Audio_Model()\n",
    "\n",
    "test_model = torch.load(model_path)\n",
    "\n",
    "\n",
    "# test_model = torch.load(model_path)\n",
    "\n",
    "test_model.eval()\n",
    "test_model = test_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a11d9",
   "metadata": {},
   "source": [
    "## processor function for input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bebdefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "\n",
    "def proccess_cnn(frame):\n",
    "        \n",
    "        dir_dict = {0: \"Down\", 1: \"Left\", 2: \"Right\", 3: \"Up\"}\n",
    "        \n",
    "        tensor = frame\n",
    "        \n",
    "\n",
    "        print(tensor.size())\n",
    "        \n",
    "#         target_size = 48000\n",
    "#         tensor = torch.nn.functional.pad(tensor, (0, target_size - tensor.size(1), 0, 0), 'constant', 0)      \n",
    "        tensor = torch.nn.functional.pad(tensor, (1, 31999), mode='constant', value=0)\n",
    "        \n",
    "        print(tensor.size())\n",
    "\n",
    "        tensor = librosa.feature.melspectrogram(y= tensor.numpy(), sr= SAMPLE_RATE, n_mels= 128)\n",
    "        tensor = librosa.power_to_db(tensor, ref= np.max)\n",
    "        tensor = torch.tensor(tensor, dtype=torch.float32)\n",
    "        \n",
    "#         tensor = nn.functional.normalize(tensor, dim=-1)\n",
    "\n",
    "        print(tensor.size())\n",
    "\n",
    "        tensor = torch.reshape(tensor, (1, 1, 128, 94))\n",
    "        \n",
    "        tensor = tensor.to(device)\n",
    "\n",
    "        output = test_model(tensor)\n",
    "\n",
    "        preds = output\n",
    "        \n",
    "        print(preds)\n",
    "        \n",
    "\n",
    "        predicted_value = torch.argmax(preds.to(\"cpu\"), dim=1)\n",
    "\n",
    "        # Return the output as a numpy array\n",
    "        final_out = dir_dict[predicted_value.detach().numpy().item()]\n",
    "        return final_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a27596",
   "metadata": {},
   "source": [
    "## Helper function for gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945a97c",
   "metadata": {},
   "source": [
    "####  Hint: in gradio type \"start\" and then submit to start recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9dc364ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7873\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "duration: 1.0310699939727783\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[9.4560e-01, 4.8155e-03, 4.9428e-02, 1.5732e-04]], device='cuda:0')\n",
      "Recording...\n",
      "duration: 1.0319890975952148\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[9.8919e-01, 9.9456e-04, 9.8091e-03, 3.6055e-06]], device='cuda:0')\n",
      "Recording...\n",
      "duration: 1.0321147441864014\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[1.2736e-01, 8.7122e-01, 1.4286e-03, 4.7970e-09]], device='cuda:0')\n",
      "Recording...\n",
      "duration: 1.0313353538513184\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[2.5788e-03, 1.8502e-02, 9.7881e-01, 1.1439e-04]], device='cuda:0')\n",
      "Recording...\n",
      "duration: 1.0310730934143066\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[4.6988e-08, 8.3816e-08, 1.0997e-02, 9.8900e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def transcribe_audio(text):\n",
    "    if text == \"start\":\n",
    "        input_format = pyaudio.paInt16\n",
    "        input_channels = 1\n",
    "        input_sample_rate = 16000  # Changed to 16000 samples per second\n",
    "        chunk_size = 2048\n",
    "        output_format = 'WAV'\n",
    "        output_channels = 1\n",
    "        output_sample_rate = 16000\n",
    "        output_duration = 3  # seconds\n",
    "        num_output_frames = output_sample_rate * output_duration\n",
    "\n",
    "        # Create a PyAudio object\n",
    "        audio = pyaudio.PyAudio()\n",
    "\n",
    "        print('Recording...')\n",
    "\n",
    "        # Open the microphone stream\n",
    "        stream = audio.open(format=input_format, channels=input_channels,\n",
    "                            rate=input_sample_rate, input=True, frames_per_buffer=chunk_size)\n",
    "\n",
    "        # Start the stream\n",
    "        since = time.time()\n",
    "        stream.start_stream()\n",
    "\n",
    "        # Record 3 seconds of audio\n",
    "        recorded_frames = []\n",
    "        for i in range(int(input_sample_rate / chunk_size * output_duration) - 15):\n",
    "            data = stream.read(chunk_size)\n",
    "            recorded_frames.append(data)\n",
    "\n",
    "        # Stop the stream\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f\"duration: {time_elapsed}\")\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        print('Processing...')\n",
    "\n",
    "        # Convert the recorded audio to a NumPy array\n",
    "        recorded_data = np.frombuffer(b''.join(recorded_frames), dtype=np.int16)\n",
    "        recorded_data = recorded_data[:16000]\n",
    "        sd.play(recorded_data, 16000)\n",
    "        recorded_data = recorded_data.astype(np.float16)\n",
    "        print(recorded_data.shape)\n",
    "\n",
    "        # Reshape the audio to (1, 48000) size\n",
    "        audio_tensor = torch.from_numpy(recorded_data).reshape(1, -1)\n",
    "        print(audio_tensor.size())\n",
    "        # Process the audio with the pre-trained model\n",
    "        with torch.no_grad():\n",
    "            output = proccess_cnn(audio_tensor)\n",
    "\n",
    "        return f'Predicted label: {output}'\n",
    "    else:\n",
    "        return \"invalid input\"\n",
    "\n",
    "# define the inputs and outputs for the Gradio interface\n",
    "audio_output = gr.outputs.Textbox(label=\"Output Label\")\n",
    "\n",
    "# create the Gradio interface\n",
    "gr.Interface(fn=transcribe_audio, inputs=\"text\", outputs=audio_output, title=\"Audio Classification\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23da08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5184fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.0 (SDL 2.28.0, Python 3.10.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[0.0010, 0.0791, 0.9169, 0.0030]], device='cuda:0')\n",
      "Predicted label: Right\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[9.2693e-08, 6.1461e-01, 3.8538e-01, 3.2261e-06]], device='cuda:0')\n",
      "Predicted label: Left\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[7.1141e-09, 4.0158e-01, 5.9842e-01, 2.3752e-06]], device='cuda:0')\n",
      "Predicted label: Right\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[6.5598e-07, 6.4793e-01, 3.5206e-01, 3.8826e-06]], device='cuda:0')\n",
      "Predicted label: Left\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[1.1017e-08, 7.1169e-11, 1.3374e-07, 1.0000e+00]], device='cuda:0')\n",
      "Predicted label: Up\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[4.7269e-15, 4.1729e-15, 7.0096e-07, 1.0000e+00]], device='cuda:0')\n",
      "Predicted label: Up\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[1.2729e-08, 7.9138e-13, 3.8603e-05, 9.9996e-01]], device='cuda:0')\n",
      "Predicted label: Up\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[9.9838e-01, 4.0284e-06, 1.6205e-03, 2.5236e-07]], device='cuda:0')\n",
      "Predicted label: Down\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[9.8765e-01, 3.0280e-06, 1.2311e-02, 3.8368e-05]], device='cuda:0')\n",
      "Predicted label: Down\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[1.8290e-01, 7.5805e-01, 5.9051e-02, 5.5202e-08]], device='cuda:0')\n",
      "Predicted label: Left\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[5.6522e-05, 9.7439e-01, 2.5553e-02, 2.3879e-10]], device='cuda:0')\n",
      "Predicted label: Left\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[5.9788e-09, 7.9871e-03, 9.9197e-01, 4.6881e-05]], device='cuda:0')\n",
      "Predicted label: Right\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[9.9327e-01, 2.3085e-05, 6.5239e-03, 1.8481e-04]], device='cuda:0')\n",
      "Predicted label: Down\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[8.8191e-04, 9.9737e-01, 1.7456e-03, 4.7380e-10]], device='cuda:0')\n",
      "Predicted label: Left\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[9.6811e-01, 6.8043e-05, 3.1502e-02, 3.2346e-04]], device='cuda:0')\n",
      "Predicted label: Down\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[1.5663e-05, 6.2976e-01, 3.7022e-01, 1.1715e-05]], device='cuda:0')\n",
      "Predicted label: Left\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[1.6918e-07, 4.0613e-01, 5.9387e-01, 6.7021e-06]], device='cuda:0')\n",
      "Predicted label: Right\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[8.2013e-08, 3.2022e-01, 6.7978e-01, 8.0656e-06]], device='cuda:0')\n",
      "Predicted label: Right\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[1.0822e-07, 3.0456e-01, 6.9543e-01, 1.0136e-05]], device='cuda:0')\n",
      "Predicted label: Right\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[4.3618e-07, 6.2623e-01, 3.7376e-01, 1.1780e-05]], device='cuda:0')\n",
      "Predicted label: Left\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[7.5366e-08, 9.9997e-01, 2.7948e-05, 2.6349e-12]], device='cuda:0')\n",
      "Predicted label: Left\n",
      "Recording...\n",
      "Processing...\n",
      "(16000,)\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 16000])\n",
      "torch.Size([1, 48000])\n",
      "torch.Size([1, 128, 94])\n",
      "tensor([[4.2028e-07, 9.9944e-01, 5.5848e-04, 1.6883e-08]], device='cuda:0')\n",
      "Predicted label: Left\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import pyaudio\n",
    "thread_run = 0\n",
    "input_format = pyaudio.paInt16\n",
    "input_channels = 1\n",
    "input_sample_rate = 16000  # Changed to 16000 samples per second\n",
    "chunk_size = 2048\n",
    "output_format = 'WAV'\n",
    "output_channels = 1\n",
    "output_sample_rate = 16000\n",
    "output_duration = 3  # seconds\n",
    "num_output_frames = output_sample_rate * output_duration\n",
    "\n",
    "# Create a PyAudio object\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set the screen dimensions\n",
    "SCREEN_WIDTH = 500\n",
    "SCREEN_HEIGHT = 600\n",
    "\n",
    "# Set the colors\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "RED = (255, 0, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "\n",
    "# Set the font\n",
    "FONT = pygame.font.Font(None, 36)\n",
    "\n",
    "# Set the frame rate\n",
    "FPS = 60\n",
    "\n",
    "# Set the number of lives\n",
    "LIVES = 3\n",
    "\n",
    "# Set the object spawn rate\n",
    "SPAWN_RATE = 5000  # milliseconds\n",
    "\n",
    "# Set the explosion duration\n",
    "EXPLOSION_DURATION = 50  # milliseconds\n",
    "\n",
    "# Set the score value\n",
    "SCORE_VALUE = 10\n",
    "\n",
    "# Load the background image\n",
    "background_image = pygame.image.load(\".\\\\game\\\\game\\\\sea.png\")\n",
    "\n",
    "# Load the airplane image\n",
    "airplane_image = pygame.image.load(\".\\\\game\\\\game\\\\airplane3.png\")\n",
    "\n",
    "# Load the object image\n",
    "object_image = pygame.image.load(\".\\\\game\\\\game\\\\bomb_sharif.png\")\n",
    "\n",
    "# Load the explosion image\n",
    "explosion_image = pygame.image.load(\".\\\\game\\\\game\\\\explosion.png\")\n",
    "\n",
    "# Set the game window\n",
    "screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "pygame.display.set_caption(\"Airplane Game\")\n",
    "\n",
    "# Create a clock to control the frame rate\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Define the airplane class\n",
    "class Airplane(pygame.sprite.Sprite):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image = airplane_image\n",
    "        self.rect = self.image.get_rect()\n",
    "        self.rect.centerx = SCREEN_WIDTH // 2\n",
    "        self.rect.bottom = SCREEN_HEIGHT - 10\n",
    "        self.speed_x = 0\n",
    "        self.speed_y = 0\n",
    "\n",
    "    def update(self):\n",
    "        # Move the airplane based on user input\n",
    "        self.rect.x += self.speed_x\n",
    "        self.rect.y += self.speed_y\n",
    "\n",
    "        # Keep the airplane inside the screen\n",
    "        if self.rect.left < 0:\n",
    "            self.rect.left = 0\n",
    "        elif self.rect.right > SCREEN_WIDTH:\n",
    "            self.rect.right = SCREEN_WIDTH\n",
    "        if self.rect.top < 0:\n",
    "            self.rect.top = 0\n",
    "        elif self.rect.bottom > SCREEN_HEIGHT:\n",
    "            self.rect.bottom = SCREEN_HEIGHT\n",
    "\n",
    "    def shoot(self):\n",
    "        # Create a bullet sprite and add it to the appropriate groups\n",
    "        bullet = Bullet(self.rect.centerx, self.rect.top)\n",
    "        all_sprites.add(bullet)\n",
    "        bullets.add(bullet)\n",
    "\n",
    "# Define the object class\n",
    "class Object(pygame.sprite.Sprite):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image = object_image\n",
    "        self.rect = self.image.get_rect()\n",
    "        self.rect.x = random.randint(2*self.rect.width, SCREEN_WIDTH - 2*self.rect.width)\n",
    "        self.rect.y = -self.rect.height\n",
    "        self.speed_y = 10\n",
    "\n",
    "    def update(self):\n",
    "        # Move the object down the screen\n",
    "        self.rect.y += self.speed_y\n",
    "\n",
    "        # Check if the object has collided with the airplane\n",
    "        if pygame.sprite.collide_rect(self, airplane):\n",
    "            # Create an explosion sprite and add it to the appropriate groups\n",
    "            explosion = Explosion(self.rect.center)\n",
    "            all_sprites.add(explosion)\n",
    "            explosions.add(explosion)\n",
    "\n",
    "            # Remove the object sprite\n",
    "            self.kill()\n",
    "\n",
    "            # Decrease the number of lives\n",
    "            global LIVES\n",
    "            LIVES -= 1\n",
    "\n",
    "            # End the game if there are no lives remaining\n",
    "            if LIVES == 0:\n",
    "                end_game()\n",
    "\n",
    "        # Check if the object has gone off the bottom of the screen\n",
    "        elif self.rect.top > SCREEN_HEIGHT:\n",
    "            # Remove the object sprite\n",
    "            self.kill()\n",
    "\n",
    "# Define the bullet class\n",
    "class Bullet(pygame.sprite.Sprite):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.image = pygame.Surface((3, 15))\n",
    "        self.image.fill(RED)\n",
    "        self.rect = self.image.get_rect()\n",
    "        self.rect.centerx = x\n",
    "        self.rect.bottom = y\n",
    "        self.speed_y = -50\n",
    "\n",
    "    def update(self):\n",
    "        # Move the bullet up the screen\n",
    "        self.rect.y += self.speed_y\n",
    "\n",
    "        # Remove the bullet sprite if it goes off the top of the screen\n",
    "        if self.rect.bottom < 0:\n",
    "            self.kill()\n",
    "\n",
    "# Define the explosion class\n",
    "class Explosion(pygame.sprite.Sprite):\n",
    "    def __init__(self, center):\n",
    "        super().__init__()\n",
    "        self.image = explosion_image\n",
    "        self.rect = self.image.get_rect()\n",
    "        self.rect.center = center\n",
    "        self.duration = EXPLOSION_DURATION\n",
    "\n",
    "    def update(self):\n",
    "        # Decrease the duration of the explosion\n",
    "        self.duration -= clock.tick(FPS)\n",
    "\n",
    "        # Remove the explosion sprite if the duration is zero\n",
    "        if self.duration <= 0:\n",
    "            self.kill()\n",
    "\n",
    "# Define the function to spawn objects\n",
    "def spawn_object():\n",
    "    # Create an object sprite and add it to the appropriate groups\n",
    "    obj = Object()\n",
    "    all_sprites.add(obj)\n",
    "    objects.add(obj)\n",
    "\n",
    "# Define the function to end the game\n",
    "def end_game():\n",
    "    # Create the result message\n",
    "    result_msg = \"Dr Sharifian killed us! Your score was: {}\".format(score)\n",
    "\n",
    "    # Display the result message\n",
    "    result_text = FONT.render(result_msg, True, WHITE)\n",
    "    result_rect = result_text.get_rect(center=(SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2))\n",
    "    screen.blit(result_text, result_rect)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # Wait for 3 seconds before quitting the game\n",
    "    pygame.time.delay(3000)\n",
    "    pygame.quit()\n",
    "    quit()\n",
    "\n",
    "# Create the airplane sprite and add it to the appropriate groups\n",
    "airplane = Airplane()\n",
    "all_sprites = pygame.sprite.Group()\n",
    "all_sprites.add(airplane)\n",
    "\n",
    "# Create the bullet and object groups\n",
    "bullets = pygame.sprite.Group()\n",
    "objects = pygame.sprite.Group()\n",
    "\n",
    "# Create the explosion group\n",
    "explosions = pygame.sprite.Group()\n",
    "\n",
    "# Set the initial score and time\n",
    "score = 0\n",
    "time = pygame.time.get_ticks()\n",
    "\n",
    "# Start the game loop\n",
    "running = True\n",
    "\n",
    "\n",
    "while running:\n",
    "    # Handle events\n",
    "\n",
    "    # Open the microphone stream\n",
    "    print('Recording...')\n",
    "    stream = audio.open(format=input_format, channels=input_channels, rate=input_sample_rate, input=True, frames_per_buffer=chunk_size)\n",
    "\n",
    "    # Start the stream\n",
    "#     since = time.time()\n",
    "    stream.start_stream()\n",
    "\n",
    "    # Record 3 seconds of audio\n",
    "    recorded_frames = []\n",
    "    for i in range(int(input_sample_rate / chunk_size * output_duration) - 5):\n",
    "        data = stream.read(chunk_size)\n",
    "        recorded_frames.append(data)\n",
    "\n",
    "    # Stop the stream\n",
    "#     time_elapsed = time.time() - since\n",
    "#     print(f\"duration: {time_elapsed}\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    print('Processing...')\n",
    "\n",
    "    # Convert the recorded audio to a NumPy array\n",
    "    recorded_data = np.frombuffer(b''.join(recorded_frames), dtype=np.int16)\n",
    "    recorded_data = recorded_data[:16000]\n",
    "    recorded_data = recorded_data.astype(np.float16)\n",
    "    print(recorded_data.shape)\n",
    "    \n",
    "    # Reshape the audio to (1, 48000) size\n",
    "    audio_tensor = torch.from_numpy(recorded_data).reshape(1, -1)\n",
    "    print(audio_tensor.size())\n",
    "    \n",
    "    # Process the audio with the pre-trained model\n",
    "    with torch.no_grad():\n",
    "        output = proccess_cnn(audio_tensor)\n",
    "\n",
    "    # Print the predicted label\n",
    "    \n",
    "    print(f'Predicted label: {output}')\n",
    "\n",
    "\n",
    "\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "        #     if event.key == pygame.K_LEFT:\n",
    "        #         airplane.speed_x = -10\n",
    "        #     elif event.key == pygame.K_RIGHT:\n",
    "        #         airplane.speed_x = 10\n",
    "        #     elif event.key == pygame.K_UP:\n",
    "        #         airplane.speed_y = -10\n",
    "        #     elif event.key == pygame.K_DOWN:\n",
    "        #         airplane.speed_y = 10\n",
    "            if event.key == pygame.K_SPACE:\n",
    "                airplane.shoot()\n",
    "        # elif event.type == pygame.KEYUP:\n",
    "        #     if event.key == pygame.K_LEFT and airplane.speed_x < 0:\n",
    "        #         airplane.speed_x = 0\n",
    "        #     elif event.key == pygame.K_RIGHT and airplane.speed_x > 0:\n",
    "        #         airplane.speed_x = 0\n",
    "        #     elif event.key == pygame.K_UP and airplane.speed_y < 0:\n",
    "        #         airplane.speed_y = 0\n",
    "        #     elif event.key == pygame.K_DOWN and airplane.speed_y > 0:\n",
    "        #         airplane.speed_y = 0\n",
    "    if output == \"Left\":\n",
    "        airplane.speed_x = -50\n",
    "        airplane.speed_y = 0\n",
    "    elif output == \"Right\":\n",
    "        airplane.speed_x = 50\n",
    "        airplane.speed_y = 0\n",
    "    elif output == \"Up\":\n",
    "        airplane.speed_y = -50\n",
    "        airplane.speed_x = 0 \n",
    "    elif output == \"Down\":\n",
    "        airplane.speed_x = 0\n",
    "        airplane.speed_y = 50\n",
    "    # Spawn objects every 5 seconds\n",
    "    if pygame.time.get_ticks() - time >= SPAWN_RATE:\n",
    "        spawn_object()\n",
    "        time = pygame.time.get_ticks()\n",
    "\n",
    "    # Update the sprites\n",
    "    all_sprites.update()\n",
    "\n",
    "    # Check for collisions between bullets and objects\n",
    "    hits = pygame.sprite.groupcollide(objects, bullets, True, True)\n",
    "    for hit in hits:\n",
    "        # Create an explosion sprite and add it to the appropriate groups\n",
    "        explosion = Explosion(hit.rect.center)\n",
    "        all_sprites.add(explosion)\n",
    "        explosions.add(explosion)\n",
    "\n",
    "        # Increase the score\n",
    "        score += SCORE_VALUE\n",
    "\n",
    "    # Draw the background and sprites\n",
    "    screen.blit(background_image, (0, 0))\n",
    "    all_sprites.draw(screen)\n",
    "\n",
    "    # Draw the score and lives\n",
    "    score_text = FONT.render(\"Score: {}\".format(score), True, WHITE)\n",
    "    score_rect = score_text.get_rect(topright=(SCREEN_WIDTH - 10, 10))\n",
    "    screen.blit(score_text, score_rect)\n",
    "\n",
    "    lives_text = FONT.render(\"Lives: {}\".format(LIVES), True, WHITE)\n",
    "    lives_rect = lives_text.get_rect(topleft=(10, 10))\n",
    "    screen.blit(lives_text, lives_rect)\n",
    "\n",
    "    # Update the display\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # End the game if there are no lives remaining\n",
    "    if LIVES == 0:\n",
    "        end_game()\n",
    "\n",
    "    # Control the frame rate\n",
    "    clock.tick(FPS)\n",
    "\n",
    "# Quit the game\n",
    "pygame.quit()\n",
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce53c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
